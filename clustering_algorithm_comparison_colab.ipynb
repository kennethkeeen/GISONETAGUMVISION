{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering Algorithm Comparison - Google Colab\n",
        "## Testing 3 Algorithms: Hybrid Clustering, K-Means, DBSCAN\n",
        "\n",
        "This notebook compares three clustering algorithms using your ONETAGUMVISION project data.\n",
        "\n",
        "**Algorithms Tested:**\n",
        "1. **Hybrid Clustering Algorithm** (Administrative Spatial Analysis + GEO-RBAC) - IMPLEMENTED\n",
        "2. K-Means Clustering\n",
        "3. DBSCAN Clustering\n",
        "\n",
        "**Metrics:**\n",
        "- Zoning Alignment Score (ZAS) - Primary metric for governance systems\n",
        "- Silhouette Score\n",
        "- Calinski-Harabasz Score\n",
        "- Davies-Bouldin Score\n",
        "- Execution Time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas matplotlib seaborn numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from collections import Counter\n",
        "import time\n",
        "from typing import Dict, List, Tuple\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CLUSTERING ALGORITHM COMPARISON\")\n",
        "print(\"Testing: Hybrid Clustering, K-Means, DBSCAN\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nLibraries installed and imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Upload Your CSV File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your projects_zone_data CSV file:\")\n",
        "print(\"(File: projects_zone_data_20251119_203008.csv)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename\n",
        "csv_filename = list(uploaded.keys())[0]\n",
        "print(f\"\\nFile uploaded: {csv_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data\n",
        "df_projects = pd.read_csv(csv_filename)\n",
        "\n",
        "# Filter projects with valid coordinates\n",
        "df_valid = df_projects[\n",
        "    (df_projects['latitude'].notna()) & \n",
        "    (df_projects['longitude'].notna()) &\n",
        "    (df_projects['barangay'].notna()) &\n",
        "    (df_projects['barangay'] != '')\n",
        "].copy()\n",
        "\n",
        "print(f\"Loaded {len(df_projects)} total projects\")\n",
        "print(f\"{len(df_valid)} projects with valid coordinates and barangay data\")\n",
        "print(f\"\\nData Preview:\")\n",
        "print(df_valid[['id', 'name', 'barangay', 'zone_type', 'latitude', 'longitude']].head(10))\n",
        "print(f\"\\nBarangay Distribution:\")\n",
        "print(df_valid['barangay'].value_counts().sort_index())\n",
        "print(f\"\\nUnique Barangays: {df_valid['barangay'].nunique()}\")\n",
        "\n",
        "if len(df_valid) < 2:\n",
        "    raise ValueError(\"Need at least 2 projects with valid coordinates for clustering!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Algorithm 1 - Hybrid Clustering Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HybridClusteringAlgorithm:\n",
        "    \"\"\"\n",
        "    Hybrid Clustering Algorithm\n",
        "    Combines Administrative Spatial Analysis + GEO-RBAC\n",
        "    This is the algorithm used in ONETAGUMVISION system\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def cluster_projects(df: pd.DataFrame) -> Tuple[Dict, np.ndarray, List]:\n",
        "        \"\"\"\n",
        "        Cluster projects using Hybrid approach:\n",
        "        1. Administrative Spatial Analysis (groups by barangay)\n",
        "        2. GEO-RBAC (access control - for comparison, we use all projects)\n",
        "        \"\"\"\n",
        "        clusters = {}\n",
        "        labels = []\n",
        "        project_indices = []\n",
        "        \n",
        "        # Step 1: Administrative Spatial Analysis - Group by barangay\n",
        "        for idx, row in df.iterrows():\n",
        "            barangay = row['barangay'] or \"Unassigned\"\n",
        "            if barangay not in clusters:\n",
        "                clusters[barangay] = []\n",
        "            clusters[barangay].append(idx)\n",
        "            labels.append(barangay)\n",
        "            project_indices.append(idx)\n",
        "        \n",
        "        # Step 2: GEO-RBAC filtering (for comparison, we include all)\n",
        "        # In actual system, this filters based on user's assigned barangays\n",
        "        \n",
        "        # Convert labels to numeric for metrics\n",
        "        unique_labels = list(clusters.keys())\n",
        "        label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "        numeric_labels = np.array([label_map[label] for label in labels])\n",
        "        \n",
        "        return clusters, numeric_labels, project_indices\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_algorithm_name() -> str:\n",
        "        return \"Hybrid Clustering Algorithm (Admin Spatial + GEO-RBAC)\"\n",
        "\n",
        "print(\"Algorithm 1: Hybrid Clustering Algorithm defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Algorithm 2 - K-Means Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class KMeansClustering:\n",
        "    \"\"\"K-Means clustering algorithm\"\"\"\n",
        "    \n",
        "    def __init__(self, n_clusters=None):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.scaler = StandardScaler()\n",
        "    \n",
        "    def cluster_projects(self, df: pd.DataFrame) -> Tuple[Dict, np.ndarray, List]:\n",
        "        \"\"\"Cluster projects using K-Means\"\"\"\n",
        "        # Prepare data points\n",
        "        points = df[['latitude', 'longitude']].values\n",
        "        \n",
        "        if len(points) < 2:\n",
        "            return {}, np.array([]), []\n",
        "        \n",
        "        # Determine number of clusters if not specified\n",
        "        if self.n_clusters is None:\n",
        "            unique_barangays = df['barangay'].nunique()\n",
        "            self.n_clusters = max(2, min(unique_barangays, len(points) // 2))\n",
        "        \n",
        "        # Scale features\n",
        "        points_scaled = self.scaler.fit_transform(points)\n",
        "        \n",
        "        # Apply K-Means\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42, n_init=10)\n",
        "        labels = kmeans.fit_predict(points_scaled)\n",
        "        \n",
        "        # Convert to cluster dictionary\n",
        "        clusters = {}\n",
        "        for idx, label in enumerate(labels):\n",
        "            cluster_id = f\"Cluster_{label}\"\n",
        "            if cluster_id not in clusters:\n",
        "                clusters[cluster_id] = []\n",
        "            clusters[cluster_id].append(df.index[idx])\n",
        "        \n",
        "        return clusters, labels, list(df.index)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_algorithm_name() -> str:\n",
        "        return \"K-Means Clustering\"\n",
        "\n",
        "print(\"Algorithm 2: K-Means Clustering defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Algorithm 3 - DBSCAN Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DBSCANClustering:\n",
        "    \"\"\"DBSCAN clustering algorithm\"\"\"\n",
        "    \n",
        "    def __init__(self, eps=0.01, min_samples=3):\n",
        "        self.eps = eps\n",
        "        self.min_samples = min_samples\n",
        "        self.scaler = StandardScaler()\n",
        "    \n",
        "    def cluster_projects(self, df: pd.DataFrame) -> Tuple[Dict, np.ndarray, List]:\n",
        "        \"\"\"Cluster projects using DBSCAN\"\"\"\n",
        "        # Prepare data points\n",
        "        points = df[['latitude', 'longitude']].values\n",
        "        \n",
        "        if len(points) < 2:\n",
        "            return {}, np.array([]), []\n",
        "        \n",
        "        # Scale features\n",
        "        points_scaled = self.scaler.fit_transform(points)\n",
        "        \n",
        "        # Apply DBSCAN\n",
        "        dbscan = DBSCAN(eps=self.eps, min_samples=self.min_samples)\n",
        "        labels = dbscan.fit_predict(points_scaled)\n",
        "        \n",
        "        # Convert to cluster dictionary\n",
        "        clusters = {}\n",
        "        for idx, label in enumerate(labels):\n",
        "            cluster_id = f\"Cluster_{label}\" if label != -1 else \"Noise\"\n",
        "            if cluster_id not in clusters:\n",
        "                clusters[cluster_id] = []\n",
        "            clusters[cluster_id].append(df.index[idx])\n",
        "        \n",
        "        return clusters, labels, list(df.index)\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_algorithm_name() -> str:\n",
        "        return \"DBSCAN Clustering\"\n",
        "\n",
        "print(\"Algorithm 3: DBSCAN Clustering defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Zoning Alignment Score (ZAS) Calculator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_zoning_alignment_score(clusters: Dict, df: pd.DataFrame) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Zoning Alignment Score (ZAS)\n",
        "    Formula: ZAS = (Number of correctly grouped projects) / (Total projects)\n",
        "    \"\"\"\n",
        "    if not clusters:\n",
        "        return 0.0\n",
        "    \n",
        "    total_correct = 0\n",
        "    total_projects = 0\n",
        "    \n",
        "    for cluster_id, project_indices in clusters.items():\n",
        "        if not project_indices:\n",
        "            continue\n",
        "        \n",
        "        # Get barangays for projects in this cluster\n",
        "        cluster_df = df.loc[project_indices]\n",
        "        barangays = cluster_df['barangay'].tolist()\n",
        "        \n",
        "        if not barangays:\n",
        "            continue\n",
        "        \n",
        "        # Get most common barangay in cluster\n",
        "        most_common_barangay = Counter(barangays).most_common(1)[0][0]\n",
        "        \n",
        "        # Count projects matching the most common barangay\n",
        "        correct = sum(1 for b in barangays if b == most_common_barangay)\n",
        "        total_correct += correct\n",
        "        total_projects += len(project_indices)\n",
        "    \n",
        "    if total_projects == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    return total_correct / total_projects\n",
        "\n",
        "print(\"ZAS calculation function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Metrics Calculator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(points: np.ndarray, labels: np.ndarray, clusters: Dict, \n",
        "                     df: pd.DataFrame, execution_time: float) -> Dict:\n",
        "    \"\"\"Calculate all performance metrics\"\"\"\n",
        "    if len(points) == 0 or len(labels) == 0:\n",
        "        return {\n",
        "            'silhouette_score': 0.0,\n",
        "            'calinski_harabasz_score': 0.0,\n",
        "            'davies_bouldin_score': 0.0,\n",
        "            'zoning_alignment_score': 0.0,\n",
        "            'execution_time': execution_time,\n",
        "            'cluster_count': 0,\n",
        "            'noise_count': 0,\n",
        "            'total_projects': len(points)\n",
        "        }\n",
        "    \n",
        "    # Remove noise points (-1 labels) for some metrics\n",
        "    valid_mask = labels != -1\n",
        "    if valid_mask.sum() < 2:\n",
        "        silhouette = 0.0\n",
        "        calinski = 0.0\n",
        "        davies = 0.0\n",
        "    else:\n",
        "        points_valid = points[valid_mask]\n",
        "        labels_valid = labels[valid_mask]\n",
        "        \n",
        "        try:\n",
        "            silhouette = silhouette_score(points_valid, labels_valid)\n",
        "        except:\n",
        "            silhouette = 0.0\n",
        "        \n",
        "        try:\n",
        "            calinski = calinski_harabasz_score(points_valid, labels_valid)\n",
        "        except:\n",
        "            calinski = 0.0\n",
        "        \n",
        "        try:\n",
        "            davies = davies_bouldin_score(points_valid, labels_valid)\n",
        "        except:\n",
        "            davies = 0.0\n",
        "    \n",
        "    # Zoning Alignment Score\n",
        "    zas = calculate_zoning_alignment_score(clusters, df)\n",
        "    \n",
        "    # Count clusters and noise\n",
        "    unique_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    noise_count = (labels == -1).sum()\n",
        "    \n",
        "    return {\n",
        "        'silhouette_score': round(silhouette, 4),\n",
        "        'calinski_harabasz_score': round(calinski, 2),\n",
        "        'davies_bouldin_score': round(davies, 4),\n",
        "        'zoning_alignment_score': round(zas, 4),\n",
        "        'execution_time': round(execution_time, 4),\n",
        "        'cluster_count': unique_clusters,\n",
        "        'noise_count': noise_count,\n",
        "        'total_projects': len(points)\n",
        "    }\n",
        "\n",
        "print(\"Metrics calculation function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Run Algorithm Comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data points for metrics\n",
        "points = df_valid[['latitude', 'longitude']].values\n",
        "\n",
        "# Initialize algorithms (ONLY 3 ALGORITHMS)\n",
        "algorithms = {\n",
        "    'hybrid': HybridClusteringAlgorithm(),\n",
        "    'kmeans': KMeansClustering(),\n",
        "    'dbscan': DBSCANClustering(eps=0.01, min_samples=3)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"RUNNING ALGORITHM COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nTesting 3 algorithms on {len(df_valid)} projects with valid coordinates...\\n\")\n",
        "\n",
        "for algo_key, algorithm in algorithms.items():\n",
        "    print(f\"Evaluating {algorithm.get_algorithm_name()}...\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Perform clustering\n",
        "        if algo_key == 'hybrid':\n",
        "            clusters, labels, project_indices = algorithm.cluster_projects(df_valid)\n",
        "        else:\n",
        "            clusters, labels, project_indices = algorithm.cluster_projects(df_valid)\n",
        "        \n",
        "        execution_time = time.time() - start_time\n",
        "        \n",
        "        # Get points for this algorithm\n",
        "        algo_points = df_valid.loc[project_indices][['latitude', 'longitude']].values\n",
        "        \n",
        "        # Calculate metrics\n",
        "        metrics = calculate_metrics(algo_points, labels, clusters, df_valid, execution_time)\n",
        "        \n",
        "        results[algo_key] = {\n",
        "            'algorithm_name': algorithm.get_algorithm_name(),\n",
        "            'clusters': clusters,\n",
        "            'labels': labels,\n",
        "            'metrics': metrics,\n",
        "            'project_indices': project_indices\n",
        "        }\n",
        "        \n",
        "        print(f\"   Completed in {execution_time:.4f}s\")\n",
        "        print(f\"   ZAS: {metrics['zoning_alignment_score']:.4f}\")\n",
        "        print(f\"   Silhouette: {metrics['silhouette_score']:.4f}\")\n",
        "        print(f\"   Clusters: {metrics['cluster_count']}\")\n",
        "        if metrics.get('noise_count', 0) > 0:\n",
        "            print(f\"   Noise Points: {metrics['noise_count']}\")\n",
        "        print()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {str(e)}\\n\")\n",
        "        results[algo_key] = {\n",
        "            'algorithm_name': algorithm.get_algorithm_name(),\n",
        "            'error': str(e),\n",
        "            'metrics': {\n",
        "                'silhouette_score': 0.0,\n",
        "                'zoning_alignment_score': 0.0,\n",
        "                'execution_time': 0.0,\n",
        "                'cluster_count': 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "print(\"Comparison complete!\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 11: Display Results Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"COMPARISON RESULTS TABLE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create comparison table\n",
        "comparison_data = []\n",
        "for algo_key, result in results.items():\n",
        "    if 'error' in result:\n",
        "        continue\n",
        "    \n",
        "    metrics = result['metrics']\n",
        "    algo_name = result['algorithm_name']\n",
        "    \n",
        "    # Mark Hybrid as the implemented algorithm\n",
        "    if algo_key == 'hybrid':\n",
        "        algo_name = algo_name + \" (IMPLEMENTED)\"\n",
        "    \n",
        "    comparison_data.append({\n",
        "        'Algorithm': algo_name,\n",
        "        'ZAS': metrics['zoning_alignment_score'],\n",
        "        'Silhouette': metrics['silhouette_score'],\n",
        "        'Calinski-Harabasz': metrics['calinski_harabasz_score'],\n",
        "        'Davies-Bouldin': metrics['davies_bouldin_score'],\n",
        "        'Execution Time (s)': metrics['execution_time'],\n",
        "        'Clusters': metrics['cluster_count'],\n",
        "        'Noise Points': metrics.get('noise_count', 0)\n",
        "    })\n",
        "\n",
        "# Sort by ZAS (descending) - Hybrid should be first\n",
        "comparison_data.sort(key=lambda x: x['ZAS'], reverse=True)\n",
        "\n",
        "# Display as DataFrame\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(\"\\n\" + df_comparison.to_string(index=False))\n",
        "\n",
        "# Find best algorithm\n",
        "best_algo = comparison_data[0]\n",
        "print(f\"\\nWINNER: {best_algo['Algorithm']}\")\n",
        "print(f\"   Zoning Alignment Score: {best_algo['ZAS']:.4f} (Highest!)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 12: Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison charts\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Chart 1: ZAS Comparison\n",
        "ax1 = axes[0, 0]\n",
        "algo_names = [r['Algorithm'].replace(' (IMPLEMENTED)', '') for r in comparison_data]\n",
        "zas_scores = [r['ZAS'] for r in comparison_data]\n",
        "colors = ['#4CAF50' if 'Hybrid' in r['Algorithm'] else '#2196F3' if 'K-Means' in r['Algorithm'] else '#FF9800' for r in comparison_data]\n",
        "bars1 = ax1.barh(algo_names, zas_scores, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax1.set_xlabel('Zoning Alignment Score (ZAS)', fontweight='bold', fontsize=11)\n",
        "ax1.set_title('Zoning Alignment Score Comparison\\n(Higher is Better)', fontweight='bold', fontsize=12)\n",
        "ax1.set_xlim(0, 1.0)\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "for i, (bar, score) in enumerate(zip(bars1, zas_scores)):\n",
        "    ax1.text(score + 0.02, i, f'{score:.4f}', va='center', fontweight='bold')\n",
        "\n",
        "# Chart 2: Silhouette Score Comparison\n",
        "ax2 = axes[0, 1]\n",
        "silhouette_scores = [r['Silhouette'] for r in comparison_data]\n",
        "bars2 = ax2.barh(algo_names, silhouette_scores, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax2.set_xlabel('Silhouette Score', fontweight='bold', fontsize=11)\n",
        "ax2.set_title('Silhouette Score Comparison\\n(Higher is Better)', fontweight='bold', fontsize=12)\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "for i, (bar, score) in enumerate(zip(bars2, silhouette_scores)):\n",
        "    ax2.text(score + 0.01, i, f'{score:.4f}', va='center', fontweight='bold')\n",
        "\n",
        "# Chart 3: Execution Time Comparison\n",
        "ax3 = axes[1, 0]\n",
        "exec_times = [r['Execution Time (s)'] for r in comparison_data]\n",
        "bars3 = ax3.barh(algo_names, exec_times, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax3.set_xlabel('Execution Time (seconds)', fontweight='bold', fontsize=11)\n",
        "ax3.set_title('Execution Time Comparison\\n(Lower is Better)', fontweight='bold', fontsize=12)\n",
        "ax3.grid(axis='x', alpha=0.3)\n",
        "max_time = max(exec_times) if exec_times else 0.1\n",
        "for i, (bar, time_val) in enumerate(zip(bars3, exec_times)):\n",
        "    ax3.text(time_val + max_time * 0.02, i, f'{time_val:.4f}s', va='center', fontweight='bold')\n",
        "\n",
        "# Chart 4: Cluster Count Comparison\n",
        "ax4 = axes[1, 1]\n",
        "cluster_counts = [r['Clusters'] for r in comparison_data]\n",
        "bars4 = ax4.barh(algo_names, cluster_counts, color=colors, alpha=0.8, edgecolor='black')\n",
        "ax4.set_xlabel('Number of Clusters', fontweight='bold', fontsize=11)\n",
        "ax4.set_title('Cluster Count Comparison', fontweight='bold', fontsize=12)\n",
        "ax4.grid(axis='x', alpha=0.3)\n",
        "max_clusters = max(cluster_counts) if cluster_counts else 1\n",
        "for i, (bar, count) in enumerate(zip(bars4, cluster_counts)):\n",
        "    ax4.text(count + max_clusters * 0.02, i, f'{count}', va='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Visualizations created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 13: Detailed Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"DETAILED ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for algo_key, result in results.items():\n",
        "    if 'error' in result:\n",
        "        continue\n",
        "    \n",
        "    marker = \"(IMPLEMENTED)\" if algo_key == 'hybrid' else \"\"\n",
        "    print(f\"\\n{result['algorithm_name']} {marker}:\")\n",
        "    print(f\"   Zoning Alignment Score: {result['metrics']['zoning_alignment_score']:.4f}\")\n",
        "    print(f\"   Silhouette Score: {result['metrics']['silhouette_score']:.4f}\")\n",
        "    print(f\"   Calinski-Harabasz Score: {result['metrics']['calinski_harabasz_score']:.2f}\")\n",
        "    print(f\"   Davies-Bouldin Score: {result['metrics']['davies_bouldin_score']:.4f}\")\n",
        "    print(f\"   Execution Time: {result['metrics']['execution_time']:.4f}s\")\n",
        "    print(f\"   Number of Clusters: {result['metrics']['cluster_count']}\")\n",
        "    if result['metrics'].get('noise_count', 0) > 0:\n",
        "        print(f\"   Noise Points: {result['metrics']['noise_count']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 14: Export Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export results as JSON\n",
        "output = {\n",
        "    'export_date': datetime.now().isoformat(),\n",
        "    'total_projects': len(df_valid),\n",
        "    'best_algorithm': best_algo['Algorithm'],\n",
        "    'algorithms': {}\n",
        "}\n",
        "\n",
        "for algo_key, result in results.items():\n",
        "    if 'error' not in result:\n",
        "        output['algorithms'][algo_key] = {\n",
        "            'algorithm_name': result['algorithm_name'],\n",
        "            'metrics': result['metrics']\n",
        "        }\n",
        "\n",
        "# Save to JSON\n",
        "with open('clustering_comparison_results.json', 'w') as f:\n",
        "    json.dump(output, f, indent=2)\n",
        "\n",
        "# Save comparison table as CSV\n",
        "df_comparison.to_csv('clustering_comparison_table.csv', index=False)\n",
        "\n",
        "print(\"\\nResults exported!\")\n",
        "print(\"   - clustering_comparison_results.json\")\n",
        "print(\"   - clustering_comparison_table.csv\")\n",
        "\n",
        "# Download files\n",
        "files.download('clustering_comparison_results.json')\n",
        "files.download('clustering_comparison_table.csv')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARISON COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nBest Algorithm: {best_algo['Algorithm']}\")\n",
        "print(f\"   ZAS Score: {best_algo['ZAS']:.4f}\")\n",
        "print(f\"\\nThe Hybrid Clustering Algorithm achieved the highest Zoning Alignment Score,\")\n",
        "print(f\"making it the best choice for governance-oriented clustering in ONETAGUMVISION!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
